# py-libtea v0.3.0 Design Document

**Goal:** Migrate from requests to httpx, add `AsyncTeaClient`, introduce pagination auto-iteration, add SemVer range matching, and address deferred code quality findings from the v0.2.0 review.

**Spec version:** TEA v0.3.0-beta.2 (OpenAPI 3.1.1) — [Ecma TC54-TG1](https://tc54.org/tea/) | [GitHub](https://github.com/CycloneDX/transparency-exchange-api)

---

## Scope

### In scope (v0.3.0)

| Feature | Rationale | Effort |
|---------|-----------|--------|
| httpx migration (sync + async) | Prerequisite for async client; unlocks `ssl.SSLContext` for encrypted mTLS keys | Large |
| `AsyncTeaClient` | Enables non-blocking usage in async frameworks (FastAPI, aiohttp, CI pipelines) | Medium |
| Pagination auto-iteration | Convenience wrapper to auto-page through `search_products`, `search_product_releases`, `get_product_releases` | Small |
| SemVer range matching in endpoint selection | Current is exact-match only; spec implies "highest matching version" could support compatible ranges | Small |
| DNS-based TEI resolution | Full DNS TXT record lookup for TEI discovery, in addition to `.well-known` | Medium |
| Protocol/ABC for client interface | Enables mocking without the concrete class; improves testability for consumers | Small |
| `download_with_hashes` refactor | Reduce cyclomatic complexity; extract redirect-following and streaming into focused helpers | Small |
| `_probe_endpoint` via transport layer | Route probes through `_http.py` instead of standalone `requests.head()` | Small |
| Interactive CLI disambiguation | When multiple endpoints or discovery results match, prompt the user to choose | Small |

### Out of scope (deferred)

| Feature | Reason |
|---------|--------|
| Publisher API | Blocked on TEA spec — see `docs/FUTURE.md` |
| `extra="forbid"` on models | Would be a breaking change for consumers; `extra="ignore"` is the safer default |

---

## 1. httpx Migration

### Why

- `requests` has no native async support — the only path to `AsyncTeaClient`
- httpx provides `ssl.SSLContext` for encrypted (password-protected) mTLS private keys (blocked in v0.2.0)
- httpx has built-in HTTP/2 support (opt-in)
- httpx's transport API enables proper socket-level IP pinning (closes the DNS rebinding TOCTOU gap from v0.2.0)
- httpx's `follow_redirects` + event hooks replace our manual redirect loop in `download_with_hashes`

### Dependency changes

```toml
# Remove
"requests>=2.32.0,<3",

# Add
"httpx>=0.27.0,<1",
```

Dev dependencies:

```toml
# Remove
"responses>=0.26.0,<1",

# Add
"respx>=0.22.0,<1",     # httpx mock library
"pytest-asyncio>=0.24.0,<1",
```

### Migration strategy

The migration touches `_http.py` (core), `discovery.py` (standalone fetch), and all test files. The approach:

1. Replace `requests.Session` with `httpx.Client` (sync) in `_http.py`
2. Create `_async_http.py` with `httpx.AsyncClient` (mirrors `_http.py`)
3. Replace `requests.get()` in `discovery.py` with `httpx.get()`
4. Replace `responses` mocks with `respx` in all test files
5. Update `pyproject.toml` dependencies

### Key mapping

| requests | httpx |
|----------|-------|
| `requests.Session()` | `httpx.Client()` |
| `session.get(url, params=...)` | `client.get(url, params=...)` |
| `response.json()` | `response.json()` |
| `response.status_code` | `response.status_code` |
| `response.text` | `response.text` |
| `response.iter_content(chunk_size=N)` | `response.iter_bytes(chunk_size=N)` |
| `session.headers[...] = ...` | `client.headers[...] = ...` |
| `session.cert = (cert, key)` | `httpx.Client(cert=(cert, key))` |
| `session.verify = ca_bundle` | `httpx.Client(verify=ca_bundle)` |
| `session.auth = (user, pass)` | `httpx.Client(auth=(user, pass))` |
| `requests.ConnectionError` | `httpx.ConnectError` |
| `requests.Timeout` | `httpx.TimeoutException` |
| `requests.RequestException` | `httpx.HTTPError` |
| `HTTPAdapter(max_retries=Retry(...))` | `httpx.Client(transport=httpx.HTTPTransport(retries=N))` |

### Retry via httpx

httpx's built-in retry is simpler than urllib3's `Retry`:

```python
transport = httpx.HTTPTransport(retries=max_retries)
client = httpx.Client(transport=transport, timeout=timeout)
```

Note: httpx's transport-level retries only retry on connection failures, not on 5xx status codes. For 5xx retry we need a custom transport or event hook:

```python
class RetryTransport(httpx.BaseTransport):
    """Transport that retries on 5xx responses with exponential backoff."""

    def __init__(
        self,
        *,
        max_retries: int = 3,
        backoff_factor: float = 0.5,
        status_forcelist: frozenset[int] = frozenset({500, 502, 503, 504}),
    ):
        self._wrapped = httpx.HTTPTransport()
        self._max_retries = max_retries
        self._backoff_factor = backoff_factor
        self._status_forcelist = status_forcelist

    def handle_request(self, request: httpx.Request) -> httpx.Response:
        import time

        last_response = None
        for attempt in range(self._max_retries + 1):
            response = self._wrapped.handle_request(request)
            if response.status_code not in self._status_forcelist:
                return response
            last_response = response
            if attempt < self._max_retries:
                delay = self._backoff_factor * (2 ** attempt)
                time.sleep(delay)
        return last_response
```

Async variant uses `httpx.AsyncHTTPTransport` and `asyncio.sleep`.

### mTLS with encrypted keys

The v0.2.0 limitation (no encrypted private keys) is resolved:

```python
import ssl

ssl_context = ssl.create_default_context()
ssl_context.load_cert_chain(
    certfile=str(mtls.client_cert),
    keyfile=str(mtls.client_key),
    password=mtls.key_password,  # New field
)
client = httpx.Client(verify=ssl_context)
```

Add optional `key_password` to `MtlsConfig`:

```python
@dataclass(frozen=True)
class MtlsConfig:
    client_cert: Path
    client_key: Path
    ca_bundle: Path | None = None
    key_password: str | None = None  # New: for encrypted private keys
```

### DNS rebinding fix via transport

The TOCTOU gap documented in v0.2.0 can be closed with httpx's transport API. A custom transport can pin the resolved IP and reject internal addresses at the socket level:

```python
class SsrfSafeTransport(httpx.BaseTransport):
    """Transport that validates resolved IPs before connecting."""

    def handle_request(self, request: httpx.Request) -> httpx.Response:
        hostname = request.url.host
        # Resolve and validate IPs
        for addr_info in socket.getaddrinfo(hostname, request.url.port):
            ip = ipaddress.ip_address(addr_info[4][0])
            if _is_internal_ip(ip):
                raise TeaValidationError(f"SSRF blocked: {hostname} resolves to {ip}")
        # Pin resolved IP in the request
        return self._wrapped.handle_request(request)
```

This eliminates the TOCTOU gap because the transport controls the actual connection.

### Testing

- Replace all `@responses.activate` with `respx.mock`
- respx syntax: `respx.get(url).respond(json={...})`
- Async tests use `@pytest.mark.asyncio` + `respx.mock`

---

## 2. AsyncTeaClient

### Design

Mirror the sync `TeaClient` API with `async`/`await`. Both clients share:
- Models (Pydantic)
- Exception hierarchy
- Validation helpers (`_validate`, `_validate_list`, `_validate_path_segment`)
- Discovery logic (sync `fetch_well_known` stays; add `async_fetch_well_known`)

### File structure

```
libtea/
    _http.py              # Sync httpx client (migrated from requests)
    _async_http.py        # Async httpx client (new)
    client.py             # TeaClient (sync, uses _http.py)
    async_client.py       # AsyncTeaClient (new, uses _async_http.py)
    discovery.py          # Add async_fetch_well_known
```

### API surface

```python
class AsyncTeaClient:
    def __init__(self, base_url: str, *, token=None, basic_auth=None, timeout=30.0, mtls=None): ...

    @classmethod
    async def from_well_known(cls, domain: str, *, ...) -> Self: ...

    async def discover(self, tei: str) -> list[DiscoveryInfo]: ...
    async def get_product(self, uuid: str) -> Product: ...
    async def get_product_releases(self, uuid: str, *, page_offset=0, page_size=100) -> PaginatedProductReleaseResponse: ...
    async def search_products(self, id_type: str, id_value: str, *, ...) -> PaginatedProductResponse: ...
    # ... all other methods mirror TeaClient ...

    # Pagination iterators (see section 3)
    async def iter_products(self, id_type: str, id_value: str, *, page_size=100) -> AsyncIterator[Product]: ...
    async def iter_product_releases(self, uuid: str, *, page_size=100) -> AsyncIterator[ProductRelease]: ...

    async def download_artifact(self, url: str, dest: Path, *, verify_checksums=None, max_download_bytes=None) -> Path: ...

    async def close(self) -> None: ...
    async def __aenter__(self) -> Self: ...
    async def __aexit__(self, *args) -> None: ...
```

### Shared code

Extract shared logic into `_shared.py` to avoid duplication between sync and async clients:

```python
# libtea/_shared.py
"""Shared validation and utility functions for sync and async clients."""

_SAFE_PATH_CHARS = frozenset(...)
_MAX_PAGE_SIZE = 10000
_WEAK_HASH_ALGORITHMS = frozenset({"MD5", "SHA-1"})

def _validate(model_cls, data): ...
def _validate_list(model_cls, data): ...
def _validate_path_segment(value, name="uuid"): ...
def _validate_page_size(page_size): ...
def _validate_page_offset(page_offset): ...
def _validate_collection_version(version): ...
def _verify_checksums(checksums, computed, url, dest): ...
```

Both `client.py` and `async_client.py` import from `_shared.py`.

### Public exports

Add to `__init__.py`:

```python
from libtea.async_client import AsyncTeaClient

__all__ = [
    # ... existing ...
    "AsyncTeaClient",
]
```

### Testing

- `tests/test_async_client.py` — mirrors `test_client.py` with `@pytest.mark.asyncio`
- `tests/test_async_http.py` — mirrors `test_http.py` with async respx mocks
- Shared test fixtures in `conftest.py` for both sync and async

---

## 3. Pagination Auto-Iteration

### Problem

Currently, paginated endpoints (`search_products`, `search_product_releases`, `get_product_releases`) return a single page. Consumers must manually loop with `page_offset`.

### Design

Add iterator methods that auto-page through results:

```python
# Sync
class TeaClient:
    def iter_products(
        self, id_type: str, id_value: str, *, page_size: int = 100
    ) -> Iterator[Product]:
        """Iterate over all products matching the identifier, auto-paging."""
        page_offset = 0
        while True:
            page = self.search_products(id_type, id_value, page_offset=page_offset, page_size=page_size)
            yield from page.results
            if len(page.results) < page_size:
                break
            page_offset += page_size

    def iter_product_releases_by_id(
        self, id_type: str, id_value: str, *, page_size: int = 100
    ) -> Iterator[ProductRelease]:
        """Iterate over all product releases matching the identifier, auto-paging."""
        page_offset = 0
        while True:
            page = self.search_product_releases(id_type, id_value, page_offset=page_offset, page_size=page_size)
            yield from page.results
            if len(page.results) < page_size:
                break
            page_offset += page_size

    def iter_product_releases(
        self, uuid: str, *, page_size: int = 100
    ) -> Iterator[ProductRelease]:
        """Iterate over all releases for a product, auto-paging."""
        page_offset = 0
        while True:
            page = self.get_product_releases(uuid, page_offset=page_offset, page_size=page_size)
            yield from page.results
            if len(page.results) < page_size:
                break
            page_offset += page_size
```

```python
# Async
class AsyncTeaClient:
    async def iter_products(
        self, id_type: str, id_value: str, *, page_size: int = 100
    ) -> AsyncIterator[Product]:
        page_offset = 0
        while True:
            page = await self.search_products(id_type, id_value, page_offset=page_offset, page_size=page_size)
            for item in page.results:
                yield item
            if len(page.results) < page_size:
                break
            page_offset += page_size
```

### Stop condition

The TEA spec pagination response includes `totalResults`. We use the simpler heuristic: stop when a page returns fewer results than `page_size`. This avoids relying on `totalResults` being accurate (some servers may not populate it).

### CLI integration

Add `--all` flag to search commands:

```
tea-cli search-products --id-type PURL --id-value "pkg:pypi/requests" --all
```

When `--all` is set, use the iterator and stream results as NDJSON (one JSON object per line) to avoid buffering the entire result set.

### Testing

- Mock multi-page responses (3 pages of data)
- Verify iteration stops on last page
- Verify empty result set yields nothing
- Verify async iteration matches sync behavior

---

## 4. SemVer Range Matching

### Current behavior

`select_endpoints()` uses exact SemVer equality: the client asks for `0.3.0-beta.2`, the server must advertise exactly that string.

### Proposed behavior

Support compatible version ranges. A client requesting `0.3.0` should match any `0.3.x` endpoint (per SemVer compatibility). Pre-release versions remain exact-match only (per SemVer 2.0.0 spec: pre-releases have lower precedence and are not interchangeable).

```python
def _is_compatible(target: _SemVer, candidate: _SemVer) -> bool:
    """Check if candidate is compatible with target per SemVer.

    Rules:
    - Pre-release targets require exact match (0.3.0-beta.2 != 0.3.0-beta.3)
    - Release targets match any candidate with same major.minor (0.3.0 matches 0.3.1)
    - Major version 0 is special: 0.x.y only matches 0.x.z (not 0.y.z)
    """
    if target.prerelease:
        return candidate == target
    if target.major == 0:
        return candidate.major == 0 and candidate.minor == target.minor and not candidate.prerelease
    return candidate.major == target.major and candidate.minor >= target.minor and not candidate.prerelease
```

### Backward compatibility

This is additive — exact matches still work. Consumers who pass `0.3.0-beta.2` get the same behavior as v0.2.0. Only release version requests (`1.0.0`) gain range matching.

### Testing

- `0.3.0` matches `0.3.0`, `0.3.1`, `0.3.99` but NOT `0.4.0`
- `0.3.0-beta.2` matches ONLY `0.3.0-beta.2` (exact)
- `1.0.0` matches `1.0.0`, `1.1.0`, `1.99.0` but NOT `2.0.0`
- Among multiple matches, highest version + highest priority wins

---

## 5. DNS-Based TEI Resolution

### Current behavior

TEI resolution uses only the `.well-known/tea` HTTP endpoint. The TEA spec also defines a DNS TXT record mechanism.

### Spec requirement

From `discovery/readme.md`:

> A DNS TXT record at `_tea.<domain>` MAY contain a JSON pointer to the TEA endpoint(s).

### Implementation

Add `resolve_tei_dns()` to `discovery.py`:

```python
import dns.resolver  # dnspython

def resolve_tei_dns(domain: str) -> TeaWellKnown | None:
    """Attempt DNS TXT record resolution for TEA discovery.

    Queries _tea.<domain> for TXT records containing a JSON well-known document.

    Returns:
        Parsed TeaWellKnown if found, None if no TXT record exists.

    Raises:
        TeaDiscoveryError: If TXT record exists but contains invalid data.
    """
    try:
        answers = dns.resolver.resolve(f"_tea.{domain}", "TXT")
    except (dns.resolver.NXDOMAIN, dns.resolver.NoAnswer, dns.resolver.NoNameservers):
        return None

    for rdata in answers:
        txt = b"".join(rdata.strings).decode("utf-8")
        try:
            data = json.loads(txt)
            return TeaWellKnown.model_validate(data)
        except (json.JSONDecodeError, ValidationError) as exc:
            raise TeaDiscoveryError(f"Invalid TEA DNS TXT record at _tea.{domain}: {exc}") from exc

    return None
```

### New optional dependency

```toml
[project.optional-dependencies]
dns = ["dnspython>=2.6.0,<3"]
```

The DNS resolution is opt-in. If `dnspython` is not installed, `resolve_tei_dns()` raises an `ImportError` with a clear message.

### Discovery flow update

Update `TeaClient.from_well_known()` to try DNS first, then fall back to HTTP:

```python
@classmethod
def from_well_known(cls, domain, *, prefer_dns=False, **kwargs):
    well_known = None
    if prefer_dns:
        try:
            well_known = resolve_tei_dns(domain)
        except ImportError:
            logger.info("dnspython not installed, skipping DNS resolution")
        except TeaDiscoveryError:
            logger.info("DNS resolution failed, falling back to HTTP")

    if well_known is None:
        well_known = fetch_well_known(domain, **kwargs)

    # ... rest of endpoint selection and failover ...
```

### Testing

- Mock DNS responses with `dnspython`'s test utilities
- Test fallback when no TXT record exists
- Test invalid TXT record raises `TeaDiscoveryError`
- Test `prefer_dns=True` tries DNS first
- Test missing `dnspython` is handled gracefully

---

## 6. Protocol/ABC for Client Interface

### Problem

Consumers who want to mock `TeaClient` in their tests must either mock the concrete class or use `unittest.mock.MagicMock`. A protocol enables type-safe mocking.

### Implementation

Add `libtea/protocols.py`:

```python
from typing import Protocol, Iterator, runtime_checkable
from pathlib import Path
from libtea.models import (
    Product, ProductRelease, Component, Release, Collection,
    ComponentReleaseWithCollection, Artifact, DiscoveryInfo,
    PaginatedProductResponse, PaginatedProductReleaseResponse,
    CLE, Checksum,
)

@runtime_checkable
class TeaClientProtocol(Protocol):
    """Protocol for TEA consumer clients (sync)."""

    def discover(self, tei: str) -> list[DiscoveryInfo]: ...
    def search_products(self, id_type: str, id_value: str, *, page_offset: int = 0, page_size: int = 100) -> PaginatedProductResponse: ...
    def search_product_releases(self, id_type: str, id_value: str, *, page_offset: int = 0, page_size: int = 100) -> PaginatedProductReleaseResponse: ...
    def get_product(self, uuid: str) -> Product: ...
    def get_product_releases(self, uuid: str, *, page_offset: int = 0, page_size: int = 100) -> PaginatedProductReleaseResponse: ...
    def get_product_release(self, uuid: str) -> ProductRelease: ...
    def get_product_release_collection_latest(self, uuid: str) -> Collection: ...
    def get_product_release_collections(self, uuid: str) -> list[Collection]: ...
    def get_product_release_collection(self, uuid: str, version: int) -> Collection: ...
    def get_component(self, uuid: str) -> Component: ...
    def get_component_releases(self, uuid: str) -> list[Release]: ...
    def get_component_release(self, uuid: str) -> ComponentReleaseWithCollection: ...
    def get_component_release_collection_latest(self, uuid: str) -> Collection: ...
    def get_component_release_collections(self, uuid: str) -> list[Collection]: ...
    def get_component_release_collection(self, uuid: str, version: int) -> Collection: ...
    def get_product_cle(self, uuid: str) -> CLE: ...
    def get_product_release_cle(self, uuid: str) -> CLE: ...
    def get_component_cle(self, uuid: str) -> CLE: ...
    def get_component_release_cle(self, uuid: str) -> CLE: ...
    def get_artifact(self, uuid: str) -> Artifact: ...
    def download_artifact(self, url: str, dest: Path, *, verify_checksums: list[Checksum] | None = None, max_download_bytes: int | None = None) -> Path: ...
    def close(self) -> None: ...
    def __enter__(self) -> "TeaClientProtocol": ...
    def __exit__(self, *args) -> None: ...
```

`AsyncTeaClientProtocol` mirrors with `async` methods and `__aenter__`/`__aexit__`.

### Export

```python
# __init__.py
from libtea.protocols import TeaClientProtocol, AsyncTeaClientProtocol
```

### Testing

- Verify `isinstance(TeaClient(...), TeaClientProtocol)` is `True`
- Verify `isinstance(AsyncTeaClient(...), AsyncTeaClientProtocol)` is `True`
- Verify a simple mock implementing the protocol passes `isinstance` check

---

## 7. Code Quality Refactors

### 7.1 `download_with_hashes` decomposition

Extract the redirect-following loop and streaming logic into focused helpers:

```python
def _follow_redirects(session, url, *, timeout, max_redirects=10):
    """Follow redirects with SSRF validation at each hop. Returns final response."""
    ...

def _stream_to_file(response, dest, hashers, *, max_bytes=None):
    """Stream response body to file, updating hashers. Returns byte count."""
    ...

def download_with_hashes(self, url, dest, algorithms=None, *, max_download_bytes=None):
    """Download a file and compute checksums on-the-fly."""
    _validate_download_url(url)
    hashers = _build_hashers(algorithms) if algorithms else {}
    dest.parent.mkdir(parents=True, exist_ok=True)
    try:
        with httpx.Client() as download_client:
            response = _follow_redirects(download_client, url, timeout=self._timeout)
            _stream_to_file(response, dest, hashers, max_bytes=max_download_bytes)
    except ...:
        dest.unlink(missing_ok=True)
        raise
    return {alg: h.hexdigest() for alg, h in hashers.items()}
```

### 7.2 `_probe_endpoint` via transport

Currently `_probe_endpoint` uses a standalone `requests.head()`. After httpx migration, route it through the same transport layer:

```python
def _probe_endpoint(url: str, timeout: float = 5.0, mtls: MtlsConfig | None = None) -> None:
    kwargs = _build_client_kwargs(mtls=mtls, timeout=timeout)
    with httpx.Client(**kwargs) as client:
        response = client.head(url)
        if response.status_code >= 500:
            raise TeaServerError(f"Server error: HTTP {response.status_code}")
```

This ensures SSRF protection, retry, and mTLS apply to probes.

---

## 8. Interactive CLI Disambiguation

### Problem

When `tea-cli inspect` discovers multiple product releases, or when `from_well_known` finds multiple endpoints, the current behavior silently uses the first result. For CLI users, this may not be the right choice.

### Implementation

Add `--interactive` / `-i` flag to relevant commands:

```python
@app.command()
def inspect(
    tei: str,
    interactive: Annotated[bool, typer.Option("--interactive", "-i", help="Prompt to choose when multiple results")] = False,
    ...
):
    discoveries = client.discover(tei)
    if interactive and len(discoveries) > 1:
        # Display numbered list and prompt
        for i, d in enumerate(discoveries):
            print(f"  [{i+1}] {d.product_release_uuid}", file=sys.stderr)
        choice = typer.prompt("Select product release", type=int, default=1)
        discoveries = [discoveries[choice - 1]]
    ...
```

Non-interactive (default) behavior is unchanged — processes all results.

---

## Dependency summary

| Package | Version | Purpose | Type | Change |
|---------|---------|---------|------|--------|
| `httpx` | >= 0.27.0, < 1 | HTTP client (sync + async) | Runtime | New |
| `pydantic` | >= 2.1.0, < 3 | Data models | Runtime | Unchanged |
| `semver` | >= 3.0.4, < 4 | SemVer comparison | Runtime | Unchanged |
| `dnspython` | >= 2.6.0, < 3 | DNS TXT resolution | Optional (`[dns]`) | New |
| `typer` | >= 0.12.0, < 1 | CLI framework | Optional (`[cli]`) | Unchanged |
| `requests` | — | — | — | **Removed** |
| `respx` | >= 0.22.0, < 1 | httpx mocking | Dev | New (replaces `responses`) |
| `pytest-asyncio` | >= 0.24.0, < 1 | Async test support | Dev | New |
| `responses` | — | — | — | **Removed** |

---

## File changes summary

| File | Changes |
|------|---------|
| `libtea/_http.py` | Migrate from `requests.Session` to `httpx.Client`, add `RetryTransport`, `SsrfSafeTransport`, encrypted mTLS |
| `libtea/_async_http.py` | **New**: async mirror of `_http.py` using `httpx.AsyncClient` |
| `libtea/_shared.py` | **New**: shared validation functions extracted from `client.py` |
| `libtea/client.py` | Import from `_shared.py`, add `iter_*` pagination methods |
| `libtea/async_client.py` | **New**: `AsyncTeaClient` with full async API + async iterators |
| `libtea/protocols.py` | **New**: `TeaClientProtocol`, `AsyncTeaClientProtocol` |
| `libtea/discovery.py` | Migrate to httpx, add `async_fetch_well_known`, add `resolve_tei_dns` |
| `libtea/cli.py` | Add `--interactive`, `--all` for search, NDJSON streaming |
| `libtea/__init__.py` | Export `AsyncTeaClient`, protocols, `resolve_tei_dns` |
| `pyproject.toml` | Swap requests→httpx, add `[dns]` extra, add dev deps, bump to 0.3.0 |
| `tests/test_http.py` | Migrate from `responses` to `respx` |
| `tests/test_async_http.py` | **New**: async transport tests |
| `tests/test_client.py` | Migrate mocks, add pagination iterator tests |
| `tests/test_async_client.py` | **New**: full async client test suite |
| `tests/test_discovery.py` | Migrate mocks, add DNS resolution tests |
| `tests/test_protocols.py` | **New**: protocol isinstance checks |
| `tests/test_cli.py` | Add interactive and `--all` tests |

---

## Migration notes

### Breaking changes

- **`requests` removed** — consumers who imported `requests.Session` from `_http.py` internals will break. Public API (`TeaClient`, `MtlsConfig`) is unchanged.
- **`MtlsConfig` gains `key_password` field** — optional, backward compatible (defaults to `None`).
- **Exception wrapping** — `TeaConnectionError` now wraps `httpx.ConnectError` instead of `requests.ConnectionError`. Consumers catching `TeaConnectionError` (not the underlying exception) are unaffected.

### Deprecations: None

### New extras

- `pip install libtea[dns]` — enables DNS-based TEI resolution
- `pip install libtea[async]` — not needed (httpx is now a core dependency)

---

## References

- TEA spec: `/tmp/transparency-exchange-api/`
- httpx docs: [encode/httpx](https://www.python-httpx.org/)
- respx docs: [lundberg/respx](https://lundberg.github.io/respx/)
- dnspython: [rthalley/dnspython](https://dnspython.readthedocs.io/)
- SemVer 2.0.0: [semver.org](https://semver.org/)
- v0.2.0 design: `docs/plans/2026-02-25-v0.2.0-design.md`
- v0.2.0 review findings: P3-3 (_probe_endpoint), P3-4 (download complexity), P3-5 (Protocol/ABC)
